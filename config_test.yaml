# Qwen QLoRA 微调配置文件
# 基于 Qwen2.5-7B-Instruct 模型进行小说创作微调

# 基础配置
model_name_or_path: "Qwen/Qwen2.5-7B-Instruct"  # 基础模型路径
dataset_path: "novel_finetuning_dataset.jsonl"  # 数据集路径（相对于项目根目录）
output_dir: "output/qwen_qlora_model"  # 输出目录
resume_from_checkpoint: true  # 是否从检查点恢复训练

# 模型配置
model_config:
  trust_remote_code: true
  torch_dtype: "auto"
  device_map: "auto"
  max_length: 1024
  model_cache_dir: "./model_cache"
  local_model_path: null
  
  # 新增：是否强制从 local_model_path 加载模型
  # false (默认): 从 model_name_or_path 指定的 Hub 仓库加载或使用缓存。
  # true: 必须从 local_model_path 加载，如果路径无效则会报错。
  force_local_load: false

# LoRA 配置（低秩适应微调）
lora_config:
  r: 8  # LoRA 秩，控制适配器的复杂度
  lora_alpha: 16  # LoRA 缩放参数，通常设为 r 的 2 倍
  lora_dropout: 0.1  # Dropout 率
  target_modules: 
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  bias: "none"

# 训练参数
training_args:
  # 基础训练参数
  num_train_epochs: 3
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  learning_rate: 2e-4
  weight_decay: 0.01
  
  # 优化器和调度器
  optim: "adamw_torch"
  lr_scheduler_type: "cosine"
  warmup_steps: 50
  max_grad_norm: 1.0
  
  # 日志和保存
  logging_steps: 10
  logging_first_step: true
  save_steps: 100
  save_total_limit: 3
  save_strategy: "steps"
  
  # 内存优化
  gradient_checkpointing: true
  dataloader_pin_memory: false
  dataloader_num_workers: 0
  remove_unused_columns: false
  
  # 精度设置
  bf16: true  # 使用 bfloat16 精度
  
  # 其他设置
  report_to: "all"  # 恢复 wandb 等日志工具
  overwrite_output_dir: false
  push_to_hub: false
